{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # For splitting data and hyperparameter tuning\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder  # For data preprocessing\n",
    "from sklearn.pipeline import Pipeline  # To create machine learning pipelines\n",
    "from scikeras.wrappers import KerasClassifier  # To integrate Keras models with scikit-learn\n",
    "import tensorflow as tf  # TensorFlow for deep learning\n",
    "from tensorflow.keras.models import Sequential  # Sequential model for building neural networks\n",
    "from tensorflow.keras.layers import Dense  # Dense layers for fully connected neural networks\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # To stop training early if performance stops improving\n",
    "import pickle  # For saving and loading Python objects (e.g., trained models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "input_features is not equal to feature_names_in_",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m onehot_encoder_geo\u001b[38;5;241m=\u001b[39mOneHotEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m geo_encoded\u001b[38;5;241m=\u001b[39monehot_encoder_geo\u001b[38;5;241m.\u001b[39mfit_transform(data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeography\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m----> 7\u001b[0m geo_encoded_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(geo_encoded,columns\u001b[38;5;241m=\u001b[39m\u001b[43monehot_encoder_geo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGeograph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat([data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeography\u001b[39m\u001b[38;5;124m'\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),geo_encoded_df],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      9\u001b[0m X\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExited\u001b[39m\u001b[38;5;124m'\u001b[39m,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\OneDrive\\app\\Desktop\\ANN_CLASSIFICATION\\venv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1227\u001b[0m, in \u001b[0;36mOneHotEncoder.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m \n\u001b[0;32m   1209\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;124;03m    Transformed feature names.\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1227\u001b[0m input_features \u001b[38;5;241m=\u001b[39m \u001b[43m_check_feature_names_in\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m cats \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_transformed_categories(i)\n\u001b[0;32m   1230\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_)\n\u001b[0;32m   1231\u001b[0m ]\n\u001b[0;32m   1233\u001b[0m name_combiner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_get_feature_name_combiner()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\OneDrive\\app\\Desktop\\ANN_CLASSIFICATION\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2468\u001b[0m, in \u001b[0;36m_check_feature_names_in\u001b[1;34m(estimator, input_features, generate_names)\u001b[0m\n\u001b[0;32m   2464\u001b[0m input_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(input_features, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m   2465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names_in_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(\n\u001b[0;32m   2466\u001b[0m     feature_names_in_, input_features\n\u001b[0;32m   2467\u001b[0m ):\n\u001b[1;32m-> 2468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features is not equal to feature_names_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features_in_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(input_features) \u001b[38;5;241m!=\u001b[39m n_features_in_:\n\u001b[0;32m   2471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2472\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features should have length equal to number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2474\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: input_features is not equal to feature_names_in_"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
    "Label_encoder_gender=LabelEncoder()\n",
    "data['Gender']=Label_encoder_gender.fit_transform(data['Gender'])\n",
    "onehot_encoder_geo=OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded=onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df=pd.DataFrame(geo_encoded,columns=onehot_encoder_geo.get_feature_names_out(['Geograph']))\n",
    "data=pd.concat([data.drop('Geography',axis=1),geo_encoded_df],axis=1)\n",
    "X=data.drop('Exited',axis=1)\n",
    "y=data['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "\n",
    "# Step 2: Drop irrelevant columns\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# Step 3: Encode the Gender column using LabelEncoder\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "# Step 4: One-hot encode the Geography column\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "\n",
    "# Convert the encoded result into a DataFrame\n",
    "geo_encoded_df = pd.DataFrame(\n",
    "    geo_encoded, \n",
    "    columns=onehot_encoder_geo.get_feature_names_out(['Geography'])\n",
    ")\n",
    "\n",
    "# Concatenate the one-hot-encoded geography data with the main dataset\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "# Step 5: Separate features (X) and target variable (y)\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "\n",
    "# Split the data in training and testing sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# Scale these features\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)\n",
    "\n",
    "# Save the encoders and sscaler\n",
    "with open('label_encoder_Gender.pkl','wb') as file:\n",
    "    pickle.dump(label_encoder_gender,file)\n",
    "\n",
    "with open('onehot_encoder_geography.pkl','wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo,file)\n",
    "\n",
    "with open('scaler.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
